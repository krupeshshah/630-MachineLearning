{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 50,000 instances for training, 10,000 for validation, and 10,000 for testing.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split( mnist.data, mnist.target, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split( X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impoting model form sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making Instance of the models \n",
    "logisticRegr_model = LogisticRegression(solver = 'lbfgs')\n",
    "svm_cls = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=True, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [logisticRegr_model, svm_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krupesh\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVC(probability=True)\n"
     ]
    }
   ],
   "source": [
    "# Training model and Checking model training timing. \n",
    "estimators = [logisticRegr_model, svm_cls]\n",
    "training_time = []\n",
    "for estimator in estimators:\n",
    "    start_time = time.time()\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time.append(f\"Training Time {end_time - start_time}s for {estimator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Training Time 50.64327001571655s for LogisticRegression()', 'Training Time 1541.5803971290588s for SVC(probability=True)']\n"
     ]
    }
   ],
   "source": [
    "print(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Logistic regression model and Checking model training timing. \n",
    "# time1 = time.time()\n",
    "# logisticRegr_model.fit(X_train, y_train)\n",
    "# time2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVC model and Checking model training timing. \n",
    "# time3 = time.time()\n",
    "# SVC_model.fit(X_train, y_train)\n",
    "# time4 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " svm_cls training Details \n"
     ]
    }
   ],
   "source": [
    "# print(f' svm_cls training Details ')\n",
    "# estimator_pre = svm_cls.predict(X_train)\n",
    "# estimator_score = svm_cls.score(X_train, y_train)\n",
    "# estimator_pre_pro = svm_cls.predict_proba(X_train)\n",
    "# train_accuracy = accuracy_score(y_train, estimator_pre)*100\n",
    "# train_auc_roc = roc_auc_score(y_train, estimator_pre_pro)*100\n",
    "# # print(f'{estimator} training Details ')\n",
    "# print('Confusion matrix:\\n', confusion_matrix(y_train, estimator_pre))\n",
    "# print('Training accuracy: %.4f %%' % train_accuracy)\n",
    "# print('Training AUC: %.4f %%' % train_auc_roc)\n",
    "# print('Training Classification Report : \\n',classification_report(y_train, estimator_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() training Details \n",
      "step 0 : 1665346158.170049\n",
      "step 1 : 1665346158.7215734\n",
      "step 2 : 1665346159.2501614\n",
      "step 4 : 1665346159.8186414\n",
      "step 5 : 1665346160.1567373\n",
      "Confusion matrix:\n",
      " [[4810    0   10    9    7   18   25    8   28    8]\n",
      " [   1 5449   19   14    4   16    3   11   42    8]\n",
      " [  22   27 4615   66   50   16   46   43  113   18]\n",
      " [  15   14   90 4655    5  124   14   31   96   35]\n",
      " [  10   20   31    9 4655    3   34   15   28  147]\n",
      " [  44   14   34  123   39 4014   63   15  115   30]\n",
      " [  26    9   29    3   28   55 4798    4   15    3]\n",
      " [   7   17   53   21   37    6    2 4859   16  150]\n",
      " [  24   72   58  104   14  107   26   14 4410   39]\n",
      " [  16   18   13   57  114   31    3  119   33 4562]]\n",
      "Training accuracy: 0.9365 %\n",
      "Training AUC: 99.5327 %\n",
      "Training Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      4923\n",
      "           1       0.97      0.98      0.97      5567\n",
      "           2       0.93      0.92      0.93      5016\n",
      "           3       0.92      0.92      0.92      5079\n",
      "           4       0.94      0.94      0.94      4952\n",
      "           5       0.91      0.89      0.90      4491\n",
      "           6       0.96      0.97      0.96      4970\n",
      "           7       0.95      0.94      0.94      5168\n",
      "           8       0.90      0.91      0.90      4868\n",
      "           9       0.91      0.92      0.92      4966\n",
      "\n",
      "    accuracy                           0.94     50000\n",
      "   macro avg       0.94      0.94      0.94     50000\n",
      "weighted avg       0.94      0.94      0.94     50000\n",
      "\n",
      "SVC(probability=True) training Details \n",
      "step 0 : 1665346161.6397715\n",
      "step 1 : 1665346712.2734232\n",
      "step 2 : 1665347268.073354\n",
      "step 4 : 1665347851.358968\n",
      "step 5 : 1665347851.5574381\n",
      "Confusion matrix:\n",
      " [[4900    1    0    1    2    4    8    0    3    4]\n",
      " [   1 5538    9    1    4    1    1    8    1    3]\n",
      " [   6    2 4969    4    9    0    1   15    8    2]\n",
      " [   0    3   12 5002    0   16    0   15   21   10]\n",
      " [   2    9    3    0 4901    0    7    3    1   26]\n",
      " [   5    2    4   15    3 4443   11    0    3    5]\n",
      " [   7    4    1    0    5    9 4941    0    3    0]\n",
      " [   2   19   15    1   11    0    0 5094    3   23]\n",
      " [   4   14    6    9    4   10    3    3 4812    3]\n",
      " [   4    4    2   15   33    6    1   25    7 4869]]\n",
      "Training accuracy: 0.9894 %\n",
      "Training AUC: 99.9885 %\n",
      "Training Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4923\n",
      "           1       0.99      0.99      0.99      5567\n",
      "           2       0.99      0.99      0.99      5016\n",
      "           3       0.99      0.98      0.99      5079\n",
      "           4       0.99      0.99      0.99      4952\n",
      "           5       0.99      0.99      0.99      4491\n",
      "           6       0.99      0.99      0.99      4970\n",
      "           7       0.99      0.99      0.99      5168\n",
      "           8       0.99      0.99      0.99      4868\n",
      "           9       0.98      0.98      0.98      4966\n",
      "\n",
      "    accuracy                           0.99     50000\n",
      "   macro avg       0.99      0.99      0.99     50000\n",
      "weighted avg       0.99      0.99      0.99     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    print(f'{estimator} training Details ')\n",
    "    print(f'step 0 : {time.time()}')\n",
    "    estimator_pre = estimator.predict(X_train)\n",
    "    print(f'step 1 : {time.time()}')\n",
    "    estimator_score = estimator.score(X_train, y_train)\n",
    "    print(f'step 2 : {time.time()}')\n",
    "    estimator_pre_pro = estimator.predict_proba(X_train)\n",
    "    # print(f'step 3 : {time.time()}')\n",
    "    # train_accuracy = accuracy_score(y_train, estimator_pre)*100\n",
    "    print(f'step 4 : {time.time()}')\n",
    "    train_auc_roc = roc_auc_score(y_train, estimator_pre_pro,multi_class='ovr')*100\n",
    "    print(f'step 5 : {time.time()}')\n",
    "    # print(f'{estimator} training Details ')\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_train, estimator_pre))\n",
    "    print('Training accuracy: %.4f %%' % estimator_score)\n",
    "    print('Training AUC: %.4f %%' % train_auc_roc)\n",
    "    print('Training Classification Report : \\n',classification_report(y_train, estimator_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in estimators:\n",
    "    print(f'{estimator} Validation Details ')\n",
    "    estimator_pre = estimator.predict(X_val)\n",
    "    estimator_pre_pro = estimator.predict_proba(X_val)\n",
    "    train_accuracy = accuracy_score(y_val, estimator_pre)*100\n",
    "    train_auc_roc = roc_auc_score(y_val, estimator_pre_pro)*100\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_val, estimator_pre))\n",
    "    print('Validation accuracy: %.4f %%' % train_accuracy)\n",
    "    print('Validation AUC: %.4f %%' % train_auc_roc)\n",
    "    print('Validation Classification Report : \\n',classification_report(y_val, estimator_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() Testing Details \n",
      "step 0 : 1665345852.119084\n",
      "step 1 : 1665345852.3205416\n",
      "step 2 : 1665345852.4402335\n",
      "step 3 : 1665345852.47912\n",
      "Confusion matrix:\n",
      " [[ 936    0    5    0    3   10   15    5    8    1]\n",
      " [   0 1123    4    6    1    6    0    2    8    2]\n",
      " [   3   15  871   16   10    4   16    9   19    4]\n",
      " [   2    5   27  931    1   27    3   10   14   14]\n",
      " [   3    1    5    5  836    4   11    4   10   27]\n",
      " [   8    9    7   44    8  797   10    1   42   11]\n",
      " [   6    4   11    0   11   11  914    1    3    0]\n",
      " [   3    2   20    4    9    1    0  987    1   28]\n",
      " [   6   15   13   29    6   26   13    8  841   12]\n",
      " [   5    6    5   10   27    6    0   24   11  942]]\n",
      "Testing accuracy: 91.7800 %\n",
      "Testing AUC: 99.2517 %\n",
      "Testing Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       983\n",
      "           1       0.95      0.97      0.96      1152\n",
      "           2       0.90      0.90      0.90       967\n",
      "           3       0.89      0.90      0.90      1034\n",
      "           4       0.92      0.92      0.92       906\n",
      "           5       0.89      0.85      0.87       937\n",
      "           6       0.93      0.95      0.94       961\n",
      "           7       0.94      0.94      0.94      1055\n",
      "           8       0.88      0.87      0.87       969\n",
      "           9       0.90      0.91      0.91      1036\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "SVC(probability=True) Testing Details \n",
      "step 0 : 1665345853.1074383\n",
      "step 1 : 1665345968.262525\n",
      "step 2 : 1665346084.8288786\n",
      "step 3 : 1665346084.8388522\n",
      "Confusion matrix:\n",
      " [[ 974    0    2    0    1    0    2    1    3    0]\n",
      " [   0 1139    4    4    0    0    0    3    1    1]\n",
      " [   1    3  949    1    2    0    3    3    5    0]\n",
      " [   0    2   10  998    2    6    0    6    6    4]\n",
      " [   1    1    1    0  885    0    2    2    2   12]\n",
      " [   1    0    2   12    0  910    7    1    4    0]\n",
      " [   1    0    0    0    3    3  951    0    3    0]\n",
      " [   0    7    9    0    5    0    0 1026    0    8]\n",
      " [   1    4    7    8    5    7    4    4  927    2]\n",
      " [   5    5    1    6    7    1    0    5    5 1001]]\n",
      "Testing accuracy: 97.6000 %\n",
      "Testing AUC: 99.9305 %\n",
      "Testing Classification Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       983\n",
      "           1       0.98      0.99      0.98      1152\n",
      "           2       0.96      0.98      0.97       967\n",
      "           3       0.97      0.97      0.97      1034\n",
      "           4       0.97      0.98      0.97       906\n",
      "           5       0.98      0.97      0.98       937\n",
      "           6       0.98      0.99      0.99       961\n",
      "           7       0.98      0.97      0.97      1055\n",
      "           8       0.97      0.96      0.96       969\n",
      "           9       0.97      0.97      0.97      1036\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    print(f'{estimator} Testing Details ')\n",
    "    print(f'step 0 : {time.time()}')\n",
    "    estimator_pre = estimator.predict(X_test)\n",
    "    print(f'step 1 : {time.time()}')\n",
    "    estimator_pre_pro = estimator.predict_proba(X_test)\n",
    "    print(f'step 2 : {time.time()}')\n",
    "    train_accuracy = accuracy_score(y_test, estimator_pre)*100\n",
    "    print(f'step 3 : {time.time()}')\n",
    "    train_auc_roc = roc_auc_score(y_test, estimator_pre_pro, average='macro', sample_weight=None, max_fpr=None, multi_class='ovr', labels=None)*100\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, estimator_pre))\n",
    "    print('Testing accuracy: %.4f %%' % train_accuracy)\n",
    "    print('Testing AUC: %.4f %%' % train_auc_roc)\n",
    "    print('Testing Classification Report : \\n',classification_report(y_test, estimator_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Confusion Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for esimator in estimators:\n",
    "    print(f'{estimator} Error Details ')\n",
    "    cross_val = cross_val_score(esimator, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    conf_mx = confusion_matrix(y_train, cross_val)\n",
    "    print('Error Confusion Matrix: %.4f %%' % conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_hat = data.predict(X_test)\n",
    "# y_test_hat_probs = data.predict_proba(X_test)\n",
    "\n",
    "# test_accuracy = accuracy_score(y_test, y_test_hat)*100\n",
    "\n",
    "# test_auc_roc = roc_auc_score(y_test, y_test_hat_probs,average='macro', sample_weight=None, max_fpr=None, multi_class='ovr', labels=None)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = Question_two.predict(X_test)\n",
    "# y_prob= Question_two.predict_proba(X_test)\n",
    "\n",
    "# train_accuracy = accuracy_score(y_test, y_pred)*100\n",
    "# train_auc_roc = roc_auc_score(y_test, y_prob, average='macro', sample_weight=None, max_fpr=None, multi_class='ovo', labels=None)*100"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
